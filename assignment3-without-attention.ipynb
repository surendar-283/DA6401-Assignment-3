{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nimport random\n\n# For reproducibility\ndef seed_everything(seed=42):\n    \"\"\"Set random seed for all major libraries\"\"\"\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size, emb_size, hid_size, layers=1, cell='LSTM', dropout=0.0, bidirectional=False):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.bidirectional = bidirectional\n        self.cell_type = cell\n        self.layers = layers\n        self.hidden_size = hid_size\n        \n        # Output size will be doubled if bidirectional\n        self.output_size = hid_size * 2 if bidirectional else hid_size\n        \n        rnn_cls = {'LSTM': nn.LSTM, 'GRU': nn.GRU, 'RNN': nn.RNN}[cell]\n        self.rnn = rnn_cls(emb_size,\n                         hid_size,\n                         num_layers=layers,\n                         dropout=dropout if layers>1 else 0.0,\n                         batch_first=True,\n                         bidirectional=bidirectional)\n\n    def forward(self, src, lengths):\n        # src: [B, T], lengths: [B]\n        embedded = self.embedding(src)  # [B, T, E]\n        packed = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n        packed_out, hidden = self.rnn(packed)\n        outputs, _ = pad_packed_sequence(packed_out, batch_first=True)  # [B, T, H*dirs]\n        \n        # If bidirectional, we need to process hidden state properly\n        if self.bidirectional:\n            if self.cell_type == 'LSTM':\n                # For LSTM we have both hidden and cell states\n                h_n, c_n = hidden\n                # Combine forward and backward states by averaging\n                h_n = torch.add(h_n[0:self.layers], h_n[self.layers:]) / 2\n                c_n = torch.add(c_n[0:self.layers], c_n[self.layers:]) / 2\n                hidden = (h_n, c_n)\n            else:\n                # For GRU/RNN we only have hidden state\n                hidden = torch.add(hidden[0:self.layers], hidden[self.layers:]) / 2\n                \n        return outputs, hidden\n\n\nclass BahdanauAttention(nn.Module):\n    def __init__(self, enc_hid, dec_hid):\n        super().__init__()\n        self.attn = nn.Linear(enc_hid + dec_hid, dec_hid)\n        self.v = nn.Linear(dec_hid, 1, bias=False)\n\n    def forward(self, hidden, encoder_outputs, mask):\n        # hidden: [B, H], encoder_outputs: [B, T, H], mask: [B, T]\n        B, T, H = encoder_outputs.size()\n        hidden = hidden.unsqueeze(1).repeat(1, T, 1)               # [B, T, H]\n        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [B, T, H]\n        scores = self.v(energy).squeeze(2)                        # [B, T]\n        scores = scores.masked_fill(~mask, -1e9)\n        return torch.softmax(scores, dim=1)                       # [B, T]\n\n\nclass Decoder(nn.Module):\n    \"\"\"\n    One class, two modes:\n        • use_attn=True  – Bahdanau attention (default)\n        • use_attn=False – Plain RNN decoder (no attention)\n\n    Forward always returns (logits, hidden, attn_weights_or_None),\n    so Seq2Seq code stays unchanged.\n    \"\"\"\n    def __init__(self, vocab_size, emb_size, enc_hid, dec_hid,\n                 layers=1, cell=\"LSTM\", dropout=0.0, use_attn=False):\n        super().__init__()\n        self.use_attn = use_attn\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.cell_type = cell\n\n        # ----- dimensions depend on whether we concatenate context -----\n        if use_attn:\n            self.attention = BahdanauAttention(enc_hid, dec_hid)\n            rnn_input_dim = emb_size + enc_hid            # [E ⊕ Henc]\n            fc_input_dim  = dec_hid + enc_hid + emb_size  # [Hdec ⊕ Henc ⊕ E]\n        else:\n            rnn_input_dim = emb_size\n            fc_input_dim  = dec_hid + emb_size\n\n        rnn_cls = {\"LSTM\": nn.LSTM, \"GRU\": nn.GRU, \"RNN\": nn.RNN}[cell]\n        self.rnn = rnn_cls(rnn_input_dim, dec_hid,\n                           num_layers=layers,\n                           dropout=dropout if layers > 1 else 0.0,\n                           batch_first=True)\n        self.fc = nn.Linear(fc_input_dim, vocab_size)\n\n    def forward(self, input_token, hidden, encoder_outputs, mask):\n        \"\"\"\n        input_token : [B]\n        hidden      : tuple|tensor  initial state for this step\n        encoder_outputs : [B, Tenc, Henc]\n        mask        : [B, Tenc]  (ignored when use_attn=False)\n        \"\"\"\n        emb = self.embedding(input_token).unsqueeze(1)     # [B,1,E]\n\n        if self.use_attn:\n            # ---- additive attention ----\n            if self.cell_type == 'LSTM':\n                dec_h = hidden[0][-1]\n            else:\n                dec_h = hidden[-1]\n                \n            attn_w = self.attention(dec_h, encoder_outputs, mask)          # [B,Tenc]\n            ctx    = torch.bmm(attn_w.unsqueeze(1), encoder_outputs)        # [B,1,Henc]\n            rnn_in = torch.cat((emb, ctx), dim=2)                           # [B,1,E+Henc]\n        else:\n            ctx = None\n            attn_w = None\n            rnn_in = emb                                                    # [B,1,E]\n\n        out, hidden = self.rnn(rnn_in, hidden)       # [B,1,Hdec]\n        out = out.squeeze(1)                         # [B,Hdec]\n        emb = emb.squeeze(1)                         # [B,E]\n\n        if self.use_attn:\n            ctx = ctx.squeeze(1)                     # [B,Henc]\n            logits = self.fc(torch.cat((out, ctx, emb), dim=1))\n        else:\n            logits = self.fc(torch.cat((out, emb), dim=1))\n\n        return logits, hidden, attn_w\n\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, pad_idx, device='cpu'):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.pad_idx = pad_idx\n        self.device = device\n\n    def forward(self, src, src_lens, tgt, teacher_forcing_ratio=0.5):\n        \"\"\"\n        Enhanced forward with explicit teacher forcing ratio control\n        \"\"\"\n        enc_out, hidden = self.encoder(src, src_lens)\n        mask = (src != self.pad_idx)\n        B, T = tgt.size()\n        outputs = torch.zeros(B, T-1, self.decoder.fc.out_features, device=self.device)\n        input_tok = tgt[:, 0]  # <sos>\n        \n        for t in range(1, T):\n            out, hidden, _ = self.decoder(input_tok, hidden, enc_out, mask)\n            outputs[:, t-1] = out\n            \n            # Teacher forcing: with probability, use ground truth as next input\n            # Otherwise use predicted token\n            teacher_force = random.random() < teacher_forcing_ratio\n            if teacher_force:\n                input_tok = tgt[:, t]\n            else:\n                input_tok = out.argmax(1)\n                \n        return outputs\n\n    def infer_greedy(self, src, src_lens, tgt_vocab, max_len=50):\n        enc_out, hidden = self.encoder(src, src_lens)\n        mask = (src != self.pad_idx)\n        B = src.size(0)\n        input_tok = torch.full((B,), tgt_vocab.sos_idx, device=self.device, dtype=torch.long)\n        generated = []\n        \n        for _ in range(max_len):\n            out, hidden, _ = self.decoder(input_tok, hidden, enc_out, mask)\n            input_tok = out.argmax(1)\n            generated.append(input_tok.unsqueeze(1))\n            if (input_tok == tgt_vocab.eos_idx).all():\n                break\n                \n        return torch.cat(generated, dim=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:13:12.374074Z","iopub.execute_input":"2025-05-19T12:13:12.374428Z","iopub.status.idle":"2025-05-19T12:13:12.707929Z","shell.execute_reply.started":"2025-05-19T12:13:12.374389Z","shell.execute_reply":"2025-05-19T12:13:12.707330Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Downloading dakshina dataset\n!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:13:12.709148Z","iopub.execute_input":"2025-05-19T12:13:12.709493Z","iopub.status.idle":"2025-05-19T12:14:01.572288Z","shell.execute_reply.started":"2025-05-19T12:13:12.709470Z","shell.execute_reply":"2025-05-19T12:14:01.571612Z"}},"outputs":[{"name":"stdout","text":"--2025-05-19 12:13:12--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\nResolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 74.125.143.207, 142.250.145.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2008340480 (1.9G) [application/x-tar]\nSaving to: ‘dakshina_dataset_v1.0.tar.1’\n\ndakshina_dataset_v1 100%[===================>]   1.87G  40.5MB/s    in 49s     \n\n2025-05-19 12:14:01 (39.5 MB/s) - ‘dakshina_dataset_v1.0.tar.1’ saved [2008340480/2008340480]\n\nyes: standard output: Broken pipe\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Unzipping dataset\n!yes | tar xopf dakshina_dataset_v1.0.tar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:14:01.573200Z","iopub.execute_input":"2025-05-19T12:14:01.573489Z","iopub.status.idle":"2025-05-19T12:14:04.322577Z","shell.execute_reply.started":"2025-05-19T12:14:01.573464Z","shell.execute_reply":"2025-05-19T12:14:04.321840Z"}},"outputs":[{"name":"stdout","text":"yes: standard output: Broken pipe\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# vocab.py - Enhanced vocabulary handling\n\nimport json\nimport os\nimport pickle\n\nclass CharVocab:\n    \"\"\"\n    Character-level vocabulary class with additional features from satyabhagwan.ipynb\n    \"\"\"\n    def __init__(self, tokens=None, specials=['<pad>','<sos>','<eos>','<unk>']):\n        self.specials = specials\n        self.idx2char = list(specials) + (tokens or [])\n        self.char2idx = {ch:i for i,ch in enumerate(self.idx2char)}\n\n    @classmethod\n    def build_from_texts(cls, texts):\n        \"\"\"Build vocabulary from a list of texts\"\"\"\n        chars = sorted({c for line in texts for c in line})\n        return cls(tokens=chars)\n    \n    @classmethod\n    def build_from_file(cls, file_path, src_col='src', tgt_col='trg', is_csv=True):\n        \"\"\"\n        Build vocabulary from a data file (CSV or TSV)\n        \n        Args:\n            file_path (str): Path to the data file\n            src_col (str): Name of the source column (for CSV)\n            tgt_col (str): Name of the target column (for CSV)\n            is_csv (bool): Whether the file is CSV (True) or TSV (False)\n        \"\"\"\n        if is_csv:\n            import pandas as pd\n            df = pd.read_csv(file_path, header=None, names=[src_col, tgt_col])\n            texts = df[src_col].dropna().tolist() + df[tgt_col].dropna().tolist()\n        else:\n            texts = []\n            with open(file_path, encoding='utf-8') as f:\n                for ln in f:\n                    parts = ln.strip().split('\\t')\n                    if len(parts) >= 2:\n                        texts.extend([parts[0], parts[1]])\n        \n        return cls.build_from_texts(texts)\n\n    def save(self, path):\n        \"\"\"Save vocabulary to JSON file\"\"\"\n        with open(path, 'w', encoding='utf-8') as f:\n            json.dump(self.idx2char, f, ensure_ascii=False)\n\n    @classmethod\n    def load(cls, path):\n        \"\"\"Load vocabulary from JSON file\"\"\"\n        with open(path, encoding='utf-8') as f:\n            idx2char = json.load(f)\n        \n        inst = cls(tokens=[])\n        inst.idx2char = idx2char\n        inst.char2idx = {c:i for i,c in enumerate(idx2char)}\n        return inst\n\n    def encode(self, text, add_sos=False, add_eos=False):\n        \"\"\"\n        Convert text to a sequence of indices\n        \n        Args:\n            text (str): Input text\n            add_sos (bool): Whether to add start-of-sequence token\n            add_eos (bool): Whether to add end-of-sequence token\n        \n        Returns:\n            list: Sequence of token indices\n        \"\"\"\n        seq = []\n        if add_sos: seq.append(self.char2idx['<sos>'])\n        for c in text:\n            seq.append(self.char2idx.get(c, self.char2idx['<unk>']))\n        if add_eos: seq.append(self.char2idx['<eos>'])\n        return seq\n\n    def decode(self, idxs, strip_specials=True, join=True):\n        \"\"\"\n        Convert a sequence of indices back to text\n        \n        Args:\n            idxs (list or tensor): Sequence of indices\n            strip_specials (bool): Whether to remove special tokens\n            join (bool): Whether to join characters into a string\n            \n        Returns:\n            str or list: Decoded text as string (if join=True) or list of characters\n        \"\"\"\n        # Convert tensor to list if needed\n        if hasattr(idxs, 'tolist'):\n            idxs = idxs.tolist()\n            \n        # Convert indices to characters\n        chars = [self.idx2char[i] for i in idxs if i < len(self.idx2char)]\n        \n        # Remove special tokens if requested\n        if strip_specials:\n            chars = [c for c in chars if c not in self.specials]\n            \n        # Return as string or list\n        return ''.join(chars) if join else chars\n    \n    def batch_decode(self, batch_idxs, strip_specials=True):\n        \"\"\"\n        Decode a batch of index sequences\n        \n        Args:\n            batch_idxs (list of lists or tensor): Batch of index sequences\n            strip_specials (bool): Whether to remove special tokens\n            \n        Returns:\n            list: List of decoded strings\n        \"\"\"\n        return [self.decode(seq, strip_specials=strip_specials) for seq in batch_idxs]\n    \n    def get_stats(self):\n        \"\"\"Get vocabulary statistics\"\"\"\n        return {\n            'size': len(self.idx2char),\n            'num_specials': len(self.specials),\n            'num_chars': len(self.idx2char) - len(self.specials)\n        }\n    \n    def __len__(self):\n        return len(self.idx2char)\n\n    @property\n    def pad_idx(self): return self.char2idx['<pad>']\n    \n    @property\n    def sos_idx(self): return self.char2idx['<sos>']\n    \n    @property\n    def eos_idx(self): return self.char2idx['<eos>']\n    \n    @property\n    def unk_idx(self): return self.char2idx['<unk>']\n    \n    @property\n    def size(self): return len(self.idx2char)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:14:04.324862Z","iopub.execute_input":"2025-05-19T12:14:04.325098Z","iopub.status.idle":"2025-05-19T12:14:04.340109Z","shell.execute_reply.started":"2025-05-19T12:14:04.325075Z","shell.execute_reply":"2025-05-19T12:14:04.339520Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# data_loader.py - Enhanced data loading with support for multiple datasets\n\nimport os\nimport torch\nimport pickle\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\n# from vocab import CharVocab\n\nclass TransliterationDataset(Dataset):\n    \"\"\"A flexible dataset class that can handle  Dakshina  dataset\"\"\"\n    \n    def __init__(self, path, src_vocab, tgt_vocab, format='dakshina'):\n        \"\"\"\n        Initialize the dataset\n        \n        Args:\n            path (str): Path to the data file\n            src_vocab (CharVocab): Source vocabulary\n            tgt_vocab (CharVocab): Target vocabulary\n            format (str): Dataset format - 'dakshina'\n        \"\"\"\n        self.examples = []\n        self.format = format\n        \n        if format == 'dakshina':\n            # Dakshina format: tab-separated without header\n            for src, tgt in read_tsv(path):\n                src_ids = src_vocab.encode(src, add_sos=True, add_eos=True)\n                tgt_ids = tgt_vocab.encode(tgt, add_sos=True, add_eos=True)\n                self.examples.append((\n                    torch.tensor(src_ids, dtype=torch.long),\n                    torch.tensor(tgt_ids, dtype=torch.long)\n                ))\n        \n        else:\n            raise ValueError(f\"Unknown format: {format}. Use 'dakshina'\")\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, idx):\n        return self.examples[idx]\n\n\ndef read_tsv(path):\n    \"\"\"Read a tab-separated file with source and target text\"\"\"\n    with open(path, encoding='utf-8') as f:\n        for ln in f:\n            parts = ln.strip().split('\\t')\n            if len(parts) >= 2:\n                yield parts[1], parts[0]  # Dakshina format has target, source\n\n\ndef read_csv(path, src_col='src', tgt_col='trg'):\n    \"\"\"Read a CSV file with source and target columns\"\"\"\n    df = pd.read_csv(path)\n    for _, row in df.iterrows():\n        yield row[src_col], row[tgt_col]\n\n\ndef collate_fn(batch, src_vocab, tgt_vocab):\n    \"\"\"Collate function to handle variable-length sequences\"\"\"\n    srcs, tgts = zip(*batch)\n    srcs_p = pad_sequence(srcs, batch_first=True, padding_value=src_vocab.pad_idx)\n    tgts_p = pad_sequence(tgts, batch_first=True, padding_value=tgt_vocab.pad_idx)\n    src_lens = torch.tensor([len(s) for s in srcs], dtype=torch.long)\n    return srcs_p, src_lens, tgts_p\n\n\ndef get_dataloaders(\n        language='te', \n        dataset_format='dakshina',\n        base_path=None,\n        batch_size=64,\n        device='cpu',\n        num_workers=2,\n        prefetch_factor=4,\n        persistent_workers=True,\n        cache_dir='./cache',\n        use_cached_vocab=True\n    ):\n    \"\"\"\n    Enhanced function to load transliteration datasets with support for multiple formats\n    \n    Args:\n        language (str): Language code (e.g., 'te' for Telugu)\n        dataset_format (str): 'dakshina' \n        base_path (str): Override the default dataset path\n        batch_size (int): Batch size\n        device (str): Device to use ('cuda' or 'cpu')\n        num_workers (int): Number of data loading workers\n        prefetch_factor (int): Number of batches to prefetch\n        persistent_workers (bool): Keep workers alive between epochs\n        cache_dir (str): Directory to cache vocabularies\n        use_cached_vocab (bool): Whether to use cached vocabularies if available\n        \n    Returns:\n        tuple: (loaders dict, src_vocab, tgt_vocab)\n    \"\"\"\n    # Set up paths based on dataset format\n    if base_path is None:\n        base_path = os.path.join(\n            '/kaggle/working/dakshina_dataset_v1.0',\n            language, 'lexicons'\n        )\n\n    # Create cache directory if it doesn't exist\n    if use_cached_vocab:\n        os.makedirs(cache_dir, exist_ok=True)\n        vocab_cache_path = os.path.join(cache_dir, f\"{language}_{dataset_format}_vocab.pkl\")\n    \n    # Try to load cached vocabularies\n    if use_cached_vocab and os.path.exists(vocab_cache_path):\n        print(f\"Loading cached vocabularies from {vocab_cache_path}\")\n        with open(vocab_cache_path, 'rb') as f:\n            src_vocab, tgt_vocab = pickle.load(f)\n    else:\n        # Build vocabularies from data\n        all_src, all_tgt = [], []\n        \n        for split in ['train', 'dev']:\n            path = os.path.join(base_path, f\"{language}.translit.sampled.{split}.tsv\")\n            for s, t in read_tsv(path):\n                all_src.append(s)\n                all_tgt.append(t)\n        \n        \n        # Build vocabularies\n        src_vocab = CharVocab.build_from_texts(all_src)\n        tgt_vocab = CharVocab.build_from_texts(all_tgt)\n        \n        # Cache vocabularies\n        if use_cached_vocab:\n            with open(vocab_cache_path, 'wb') as f:\n                pickle.dump((src_vocab, tgt_vocab), f)\n    \n    # Common DataLoader arguments\n    loader_kwargs = dict(\n        batch_size=batch_size,\n        num_workers=num_workers,\n        prefetch_factor=prefetch_factor,\n        persistent_workers=persistent_workers and num_workers > 0,\n        pin_memory=(device == 'cuda')\n    )\n    \n    # Create data loaders for each split\n    loaders = {}\n    \n    \n    splits = {'train': 'train', 'dev': 'dev', 'test': 'test'}\n    for split_name, file_split in splits.items():\n        path = os.path.join(base_path, f\"{language}.translit.sampled.{file_split}.tsv\")\n        ds = TransliterationDataset(path, src_vocab, tgt_vocab, format='dakshina')\n        loaders[split_name] = DataLoader(\n            ds,\n            shuffle=(split_name == 'train'),\n            collate_fn=lambda b: collate_fn(b, src_vocab, tgt_vocab),\n            **loader_kwargs\n        )\n    \n    \n    return loaders, src_vocab, tgt_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:14:04.340753Z","iopub.execute_input":"2025-05-19T12:14:04.340963Z","iopub.status.idle":"2025-05-19T12:14:04.364793Z","shell.execute_reply.started":"2025-05-19T12:14:04.340948Z","shell.execute_reply":"2025-05-19T12:14:04.364139Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport wandb\nfrom tqdm.auto import tqdm\nimport csv\nimport pandas as pd\n\ndef compute_detailed_accuracy(model, loader, tgt_vocab, src_vocab, device):\n    \"\"\"\n    Enhanced accuracy function that returns:\n    - Overall accuracy\n    - Lists of correct and incorrect predictions for analysis\n    \"\"\"\n    model.eval()\n    correct = total = 0\n    \n    # Lists to store detailed results\n    correct_srcs = []\n    correct_tgts = []\n    correct_preds = []\n    \n    incorrect_srcs = []\n    incorrect_tgts = []\n    incorrect_preds = []\n    \n    with torch.no_grad():\n        for src, src_lens, tgt in loader:\n            src, src_lens, tgt = (x.to(device) for x in (src, src_lens, tgt))\n            pred = model.infer_greedy(src, src_lens, tgt_vocab, max_len=tgt.size(1))\n\n            # iterate over the batch\n            for b in range(src.size(0)):\n                # Convert indices to strings\n                pred_str = tgt_vocab.decode(pred[b].cpu().tolist())\n                gold_str = tgt_vocab.decode(tgt[b, 1:].cpu().tolist())  # skip <sos>\n                src_str = src_vocab.decode(src[b].cpu().tolist())\n                \n                # Check if prediction is correct\n                is_correct = (pred_str == gold_str)\n                correct += is_correct\n                \n                # Store detailed results\n                if is_correct:\n                    correct_srcs.append(src_str)\n                    correct_tgts.append(gold_str)\n                    correct_preds.append(pred_str)\n                else:\n                    incorrect_srcs.append(src_str)\n                    incorrect_tgts.append(gold_str)\n                    incorrect_preds.append(pred_str)\n                    \n            total += src.size(0)\n\n    accuracy = correct / total if total else 0.0\n    return (\n        accuracy, \n        (correct_srcs, correct_tgts, correct_preds),\n        (incorrect_srcs, incorrect_tgts, incorrect_preds)\n    )\n\ndef save_predictions_to_csv(src_list, tgt_list, pred_list, file_name):\n    \"\"\"Save prediction details to CSV file for further analysis\"\"\"\n    rows = zip(src_list, tgt_list, pred_list)\n    \n    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Source', 'Target', 'Predicted'])\n        writer.writerows(rows)\n    \n    return file_name\n\ndef train_model(\n    model, \n    loaders, \n    src_vocab, \n    tgt_vocab, \n    device,\n    config,\n    save_path=None,\n    log_to_wandb=True\n):\n    \"\"\"\n    Enhanced training function with:\n    - Teacher forcing control\n    - Detailed accuracy tracking\n    - Progress bars\n    - Optional WandB logging\n    \"\"\"\n    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n    \n    # Select optimizer based on config\n    if config.optimizer.lower() == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n    elif config.optimizer.lower() == 'nadam':\n        optimizer = optim.NAdam(model.parameters(), lr=config.lr)\n    else:\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n    \n    # Track best validation accuracy\n    best_val_acc = 0.0\n    \n    # Main training loop\n    for epoch in tqdm(range(1, config.epochs + 1), desc=\"Epochs\", position=0):\n        model.train()\n        total_loss = 0.0\n\n        # Training batches with progress bar\n        train_loader = tqdm(loaders['train'], desc=f\"Train {epoch}\", leave=False, position=1)\n        for src, src_lens, tgt in train_loader:\n            src, src_lens, tgt = src.to(device), src_lens.to(device), tgt.to(device)\n\n            optimizer.zero_grad()\n            # Use teacher forcing ratio from config\n            output = model(src, src_lens, tgt, teacher_forcing_ratio=config.teacher_forcing)\n            loss = criterion(output.reshape(-1, output.size(-1)), tgt[:,1:].reshape(-1))\n            loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            total_loss += loss.item()\n            \n        train_loader.close()\n        train_loss = total_loss / len(loaders['train'])\n\n        # Validation loss\n        val_loss = 0.0\n        val_loader = tqdm(loaders['dev'], desc=f\"Val {epoch}\", leave=False, position=1)\n        model.eval()\n        with torch.no_grad():\n            for src, src_lens, tgt in val_loader:\n                src, src_lens, tgt = src.to(device), src_lens.to(device), tgt.to(device)\n                output = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)  # No teacher forcing during validation\n                val_loss += criterion(output.reshape(-1, output.size(-1)),\n                                    tgt[:,1:].reshape(-1)).item()\n        val_loader.close()\n        val_loss /= len(loaders['dev'])\n\n        # Compute detailed accuracy metrics\n        train_results = compute_detailed_accuracy(model, loaders['train'], tgt_vocab, src_vocab, device)\n        train_acc = train_results[0]\n        \n        val_results = compute_detailed_accuracy(model, loaders['dev'], tgt_vocab, src_vocab, device)\n        val_acc = val_results[0]\n        \n        # Save model if it's the best so far\n        if val_acc > best_val_acc and save_path:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), save_path)\n            print(f\"Saved new best model with validation accuracy: {val_acc:.4f}\")\n            \n            # Save prediction analysis CSVs for best model\n            if epoch == config.epochs or epoch % 5 == 0:  # Save at last epoch or every 5 epochs\n                correct_data = val_results[1]\n                incorrect_data = val_results[2]\n                \n                save_predictions_to_csv(\n                    correct_data[0], correct_data[1], correct_data[2],\n                    f\"correct_predictions_epoch_{epoch}.csv\"\n                )\n                \n                save_predictions_to_csv(\n                    incorrect_data[0], incorrect_data[1], incorrect_data[2],\n                    f\"incorrect_predictions_epoch_{epoch}.csv\"\n                )\n\n        # Log metrics\n        print(f\"Epoch {epoch}/{config.epochs}:\")\n        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        \n        if log_to_wandb:\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': train_loss,\n                'val_loss': val_loss,\n                'train_acc': train_acc,\n                'val_acc': val_acc\n            })\n    \n    # Final evaluation on test set\n    # test_results = compute_detailed_accuracy(model, loaders['test'], tgt_vocab, src_vocab, device)\n    # test_acc = test_results[0]\n    # print(f\"Final test accuracy: {test_acc:.4f}\")\n    \n    # if log_to_wandb:\n    #     wandb.log({'test_acc': test_acc})\n    \n    # # Save final prediction analysis\n    # correct_data = test_results[1]\n    # incorrect_data = test_results[2]\n    \n    # save_predictions_to_csv(\n    #     correct_data[0], correct_data[1], correct_data[2],\n    #     \"correct_predictions_final.csv\"\n    # )\n    \n    # save_predictions_to_csv(\n    #     incorrect_data[0], incorrect_data[1], incorrect_data[2],\n    #     \"incorrect_predictions_final.csv\"\n    # )\n    test_acc=0\n    \n    return model, test_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:14:04.365613Z","iopub.execute_input":"2025-05-19T12:14:04.365842Z","iopub.status.idle":"2025-05-19T12:14:04.384826Z","shell.execute_reply.started":"2025-05-19T12:14:04.365820Z","shell.execute_reply":"2025-05-19T12:14:04.384122Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"wandb.login(key='4e3ff854ed5182f4bc02df0482250c121f645ae5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:14:04.385615Z","iopub.execute_input":"2025-05-19T12:14:04.385840Z","iopub.status.idle":"2025-05-19T12:14:04.671301Z","shell.execute_reply.started":"2025-05-19T12:14:04.385825Z","shell.execute_reply":"2025-05-19T12:14:04.670769Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# sweep_config.py - Enhanced with improved hyperparameter sweep\n\nimport wandb\nimport torch\nfrom tqdm.auto import tqdm\nimport os\nimport random\nimport numpy as np\n\n\n# Import enhanced modules\n# from models import Encoder, Decoder, Seq2Seq, seed_everything\n# from training import train_model\n# from data import get_dataloaders\n\ndef objective():\n    # Initialize WandB run\n    run = wandb.init()\n    cfg = run.config\n    \n    # Set seeds for reproducibility\n    seed_everything(cfg.seed if hasattr(cfg, 'seed') else 42)\n    \n    # Set device\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(f\"Using device: {device}\")\n    \n    # Create a unique run name based on config\n    run_name = f\"{cfg.cell}_{cfg.enc_layers}l_{cfg.emb_size}e_{cfg.hidden_size}h_\" \\\n               f\"{'bid' if cfg.bidirectional else 'uni'}_{cfg.dropout}d_\" \\\n               f\"{cfg.teacher_forcing}tf_{cfg.optimizer}\"\n    wandb.run.name = run_name\n    \n    # Load data\n    loaders, src_vocab, tgt_vocab = get_dataloaders(\n        'te',\n        batch_size=cfg.batch_size,\n        device=device\n    )\n    \n    # Create model components\n    enc = Encoder(\n        src_vocab.size, cfg.emb_size, cfg.hidden_size,\n        cfg.enc_layers, cfg.cell, cfg.dropout, \n        bidirectional=cfg.bidirectional\n    ).to(device)\n    \n    # Calculate encoder output dimension (doubled if bidirectional)\n    enc_out_dim = cfg.hidden_size * 2 if cfg.bidirectional else cfg.hidden_size\n    \n    dec = Decoder(\n        tgt_vocab.size, cfg.emb_size, enc_out_dim, cfg.hidden_size,\n        cfg.enc_layers, cfg.cell, cfg.dropout\n    ).to(device)\n    \n    model = Seq2Seq(enc, dec, pad_idx=src_vocab.pad_idx, device=device).to(device)\n    \n    # Train the model\n    best_model_path = f\"model_{run_name}.pt\"\n    _, test_acc = train_model(\n        model=model,\n        loaders=loaders,\n        src_vocab=src_vocab,\n        tgt_vocab=tgt_vocab,\n        device=device,\n        config=cfg,\n        save_path=best_model_path,\n        log_to_wandb=True\n    )\n    \n    # Log final test accuracy as summary metric\n    # wandb.run.summary['test_accuracy'] = test_acc\n    \n    # Finish the run\n    wandb.finish()\n\nif __name__ == \"__main__\":\n    # Define an enhanced sweep configuration\n    sweep_cfg = {\n        \n        'method': 'bayes',  # Use Bayesian optimization\n        'name':'Transliteration_without_Attention',\n        'metric': {'name': 'val_acc', 'goal': 'maximize'},\n        'parameters': {\n            \n            # Model architecture\n            'emb_size': {'values': [128, 256, 512]},\n            'hidden_size': {'values': [128, 256, 512, 1024]},\n            'enc_layers': {'values': [1, 2, 3, 4]},\n            'cell': {'values': ['RNN', 'GRU', 'LSTM']},  \n            'bidirectional': {'values': [True, False]},  # Bidirectional encode\n            \n            # Training parameters\n            'dropout': {'values': [0.0, 0.1, 0.2, 0.3, 0.5]},\n            'lr': {'values': [1e-4, 2e-4, 5e-4, 8e-4, 1e-3]},\n            'batch_size': {'values': [32, 64, 128]},\n            'epochs': {'values': [10, 15, 20]},\n            'teacher_forcing': {'values': [0.3, 0.5, 0.7, 1.0]},  # Explicit teacher forcing\n            'optimizer': {'values': ['Adam', 'NAdam']},  # Added optimizer options\n            # Reproducibility\n            'seed': {'values': [42, 43, 44, 45, 46]},  # Different seeds for robustness\n        }\n    }\n\n    # Start the sweep\n    sweep_id = wandb.sweep(\n        sweep_cfg,\n        entity='cs24m042-iit-madras-foundation',  # Replace with your username\n        project='DA6401-Assignment-3'\n    )\n    \n    # Run the sweep agent\n    wandb.agent(sweep_id, function=objective, count=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:26:07.935314Z","iopub.execute_input":"2025-05-19T12:26:07.936057Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: kx7x532z\nSweep URL: https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/sweeps/kx7x532z\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eesdjwbp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \temb_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0008\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 45\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_122616-eesdjwbp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/runs/eesdjwbp' target=\"_blank\">tough-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/sweeps/kx7x532z' target=\"_blank\">https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/sweeps/kx7x532z</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3' target=\"_blank\">https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/sweeps/kx7x532z' target=\"_blank\">https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/sweeps/kx7x532z</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/runs/eesdjwbp' target=\"_blank\">https://wandb.ai/cs24m042-iit-madras-foundation/DA6401-Assignment-3/runs/eesdjwbp</a>"},"metadata":{}},{"name":"stdout","text":"Using device: cuda\nLoading cached vocabularies from ./cache/te_dakshina_vocab.pkl\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epochs:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed77f5a705bf426d8c382760df81bcf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Train 1:   0%|          | 0/915 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val 1:   0%|          | 0/89 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Saved new best model with validation accuracy: 0.0554\nEpoch 1/20:\n  Train Loss: 1.2515, Train Acc: 0.0806\n  Val Loss: 2.5904, Val Acc: 0.0554\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 2:   0%|          | 0/915 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val 2:   0%|          | 0/89 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Saved new best model with validation accuracy: 0.1138\nEpoch 2/20:\n  Train Loss: 0.6541, Train Acc: 0.1946\n  Val Loss: 2.5525, Val Acc: 0.1138\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 3:   0%|          | 0/915 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val 3:   0%|          | 0/89 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Saved new best model with validation accuracy: 0.1285\nEpoch 3/20:\n  Train Loss: 0.5007, Train Acc: 0.2401\n  Val Loss: 2.6587, Val Acc: 0.1285\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 4:   0%|          | 0/915 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val 4:   0%|          | 0/89 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/20:\n  Train Loss: 0.4225, Train Acc: 0.2339\n  Val Loss: 2.7117, Val Acc: 0.1221\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 5:   0%|          | 0/915 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Val 5:   0%|          | 0/89 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5/20:\n  Train Loss: 0.3690, Train Acc: 0.2422\n  Val Loss: 2.8883, Val Acc: 0.1147\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 6:   0%|          | 0/915 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99aa6e4896b444ef88af09521b2d04f1"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# import os\n# import torch\n# import wandb\n# import argparse\n# from models import Encoder, Decoder, Seq2Seq, seed_everything\n# from data import get_dataloaders\n# from training import train_model, save_predictions_to_csv, compute_detailed_accuracy\n\n# def main(args):\n#     # Set seeds for reproducibility\n#     seed_everything(args.seed)\n    \n#     # Set device\n#     device = torch.device(args.device if torch.cuda.is_available() and args.device == 'cuda' else 'cpu')\n#     print(f\"Using device: {device}\")\n    \n#     # Initialize wandb if requested\n#     if args.use_wandb:\n#         wandb.init(\n#             project=args.wandb_project,\n#             name=args.run_name,\n#             config=vars(args)\n#         )\n    \n#     # Load datasets\n#     print(f\"Loading {args.language} data...\")\n#     loaders, src_vocab, tgt_vocab = get_dataloaders(\n#         args.language,\n#         batch_size=args.batch_size,\n#         device=args.device\n#     )\n    \n#     # Create model components\n#     print(\"Building model...\")\n#     enc = Encoder(\n#         src_vocab.size, args.emb_size, args.hidden_size,\n#         args.enc_layers, args.cell_type, args.dropout, \n#         bidirectional=args.bidirectional\n#     ).to(device)\n    \n#     # Calculate encoder output dimension (doubled if bidirectional)\n#     enc_out_dim = args.hidden_size * 2 if args.bidirectional else args.hidden_size\n    \n#     dec = Decoder(\n#         tgt_vocab.size, args.emb_size, enc_out_dim, args.hidden_size,\n#         args.enc_layers, args.cell_type, args.dropout, \n#         use_attn=args.use_attention\n#     ).to(device)\n    \n#     model = Seq2Seq(enc, dec, pad_idx=src_vocab.pad_idx, device=device).to(device)\n    \n#     # Create output directory if it doesn't exist\n#     os.makedirs(args.output_dir, exist_ok=True)\n    \n#     # Train the model\n#     print(\"Training model...\")\n#     best_model_path = os.path.join(args.output_dir, f\"{args.run_name}_best.pt\")\n#     model, test_acc = train_model(\n#         model=model,\n#         loaders=loaders,\n#         src_vocab=src_vocab,\n#         tgt_vocab=tgt_vocab,\n#         device=device,\n#         config=args,\n#         save_path=best_model_path,\n#         log_to_wandb=args.use_wandb\n#     )\n    \n#     # Save final model\n#     final_model_path = os.path.join(args.output_dir, f\"{args.run_name}_final.pt\")\n#     torch.save(model.state_dict(), final_model_path)\n#     print(f\"Saved final model to {final_model_path}\")\n    \n#     # Generate and save detailed predictions on test set\n#     print(\"Generating final predictions on test set...\")\n#     test_results = compute_detailed_accuracy(model, loaders['test'], tgt_vocab, src_vocab, device)\n#     test_acc = test_results[0]\n    \n#     correct_data = test_results[1]\n#     incorrect_data = test_results[2]\n    \n#     correct_csv = os.path.join(args.output_dir, f\"{args.run_name}_correct.csv\")\n#     incorrect_csv = os.path.join(args.output_dir, f\"{args.run_name}_incorrect.csv\")\n    \n#     save_predictions_to_csv(\n#         correct_data[0], correct_data[1], correct_data[2],\n#         correct_csv\n#     )\n    \n#     save_predictions_to_csv(\n#         incorrect_data[0], incorrect_data[1], incorrect_data[2],\n#         incorrect_csv\n#     )\n    \n#     print(f\"Final test accuracy: {test_acc:.4f}\")\n#     print(f\"Saved correct predictions to {correct_csv}\")\n#     print(f\"Saved incorrect predictions to {incorrect_csv}\")\n    \n#     if args.use_wandb:\n#         wandb.finish()\n\n# if __name__ == \"__main__\":\n#     parser = argparse.ArgumentParser(description=\"Train a seq2seq transliteration model\")\n    \n#     # Data parameters\n#     parser.add_argument(\"--language\", type=str, default=\"te\", help=\"Language code (e.g., 'te' for Telugu)\")\n#     parser.add_argument(\"--output_dir\", type=str, default=\"./output\", help=\"Directory to save models and outputs\")\n    \n#     # Model architecture\n#     parser.add_argument(\"--emb_size\", type=int, default=256, help=\"Embedding size\")\n#     parser.add_argument(\"--hidden_size\", type=int, default=512, help=\"Hidden state size\")\n#     parser.add_argument(\"--enc_layers\", type=int, default=2, help=\"Number of encoder layers\")\n#     parser.add_argument(\"--cell_type\", type=str, default=\"LSTM\", choices=[\"RNN\", \"GRU\", \"LSTM\"], help=\"RNN cell type\")\n#     parser.add_argument(\"--bidirectional\", action=\"store_true\", help=\"Use bidirectional encoder\")\n#     parser.add_argument(\"--use_attention\", action=\"store_true\", default=True, help=\"Use attention mechanism\")\n    \n#     # Training parameters\n#     parser.add_argument(\"--batch_size\", type=int, default=128, help=\"Batch size\")\n#     parser.add_argument(\"--epochs\", type=int, default=15, help=\"Number of epochs\")\n#     parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate\")\n#     parser.add_argument(\"--dropout\", type=float, default=0.3, help=\"Dropout rate\")\n#     parser.add_argument(\"--teacher_forcing\", type=float, default=0.5, help=\"Teacher forcing ratio\")\n#     parser.add_argument(\"--optimizer\", type=str, default=\"Adam\", choices=[\"Adam\", \"NAdam\"], help=\"Optimizer\")\n#     parser.add_argument(\"--seed\", type=int, default=42, help=\"Random seed\")\n#     parser.add_argument(\"--device\", type=str, default=\"cuda\", choices=[\"cuda\", \"cpu\"], help=\"Device to use\")\n    \n#     # Wandb parameters\n#     parser.add_argument(\"--use_wandb\", action=\"store_true\", help=\"Log to Weights & Biases\")\n#     parser.add_argument(\"--wandb_project\", type=str, default=\"transliteration\", help=\"WandB project name\")\n#     parser.add_argument(\"--run_name\", type=str, default=\"seq2seq_model\", help=\"Run name\")\n    \n#     args = parser.parse_args()\n#     main(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:14:04.682894Z","iopub.status.idle":"2025-05-19T12:14:04.683175Z","shell.execute_reply.started":"2025-05-19T12:14:04.683017Z","shell.execute_reply":"2025-05-19T12:14:04.683038Z"}},"outputs":[],"execution_count":null}]}